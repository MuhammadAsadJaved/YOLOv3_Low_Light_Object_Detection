{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This python file will generate ground truth files and predicted files for the required subset of classes in ../mAP folder which will be used for calculation of mAP. We have explained the code in our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import core.utils as utils\n",
    "from core.config import cfg\n",
    "from core.yolov3 import YOLOv3, decode\n",
    "\n",
    "\n",
    "INPUT_SIZE   = 416\n",
    "NUM_CLASS    = len(utils.read_class_names(cfg.YOLO.CLASSES))\n",
    "CLASSES      = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "\n",
    "\n",
    "predicted_dir_path = '../mAP/predicted'\n",
    "ground_truth_dir_path = '../mAP/ground-truth'\n",
    "if os.path.exists(predicted_dir_path): shutil.rmtree(predicted_dir_path)\n",
    "if os.path.exists(ground_truth_dir_path): shutil.rmtree(ground_truth_dir_path)\n",
    "if os.path.exists(cfg.TEST.DECTECTED_IMAGE_PATH): shutil.rmtree(cfg.TEST.DECTECTED_IMAGE_PATH)\n",
    "\n",
    "os.mkdir(predicted_dir_path)\n",
    "os.mkdir(ground_truth_dir_path)\n",
    "os.mkdir(cfg.TEST.DECTECTED_IMAGE_PATH)\n",
    "\n",
    "# Build Model\n",
    "input_layer  = tf.keras.layers.Input([INPUT_SIZE, INPUT_SIZE, 3])\n",
    "feature_maps = YOLOv3(input_layer)\n",
    "\n",
    "bbox_tensors = []\n",
    "for i, fm in enumerate(feature_maps):\n",
    "    bbox_tensor = decode(fm, i)\n",
    "    bbox_tensors.append(tf.reshape(bbox_tensor, (-1, 5+NUM_CLASS)))\n",
    "\n",
    "bbox_tensors = tf.concat(bbox_tensors, axis=0)\n",
    "model = tf.keras.Model(input_layer, bbox_tensors)\n",
    "model.summary()\n",
    "utils.load_weights(model, \"./yolov3.weights\")\n",
    "\n",
    "with open(cfg.TEST.ANNOT_PATH, 'r') as annotation_file:\n",
    "    for num, line in enumerate(annotation_file):\n",
    "        annotation = line.strip().split()\n",
    "        image_path = annotation[0]\n",
    "        image_name = image_path.split('/')[-1]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        bbox_data_gt = np.array([list(map(int, box.split(','))) for box in annotation[1:]])\n",
    "\n",
    "        if len(bbox_data_gt) == 0:\n",
    "            bboxes_gt=[]\n",
    "            classes_gt=[]\n",
    "        else:\n",
    "            bboxes_gt, classes_gt = bbox_data_gt[:, :4], bbox_data_gt[:, 4]\n",
    "        ground_truth_path = os.path.join(ground_truth_dir_path, str(num) + '.txt')\n",
    "\n",
    "        print('=> ground truth of %s:' % image_name)\n",
    "        num_bbox_gt = len(bboxes_gt)\n",
    "        with open(ground_truth_path, 'w') as f:\n",
    "            for i in range(num_bbox_gt):\n",
    "                class_name = CLASSES[classes_gt[i]]\n",
    "                xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[i]))\n",
    "                bbox_mess = ' '.join([class_name, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "                f.write(bbox_mess)\n",
    "                print('\\t' + str(bbox_mess).strip())\n",
    "        print('=> predict result of %s:' % image_name)\n",
    "        predict_result_path = os.path.join(predicted_dir_path, str(num) + '.txt')\n",
    "        # Predict Process\n",
    "        image_size = image.shape[:2]\n",
    "        image_data = utils.image_preporcess(np.copy(image), [INPUT_SIZE, INPUT_SIZE])\n",
    "        image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "        pred_bbox = model.predict(image_data)\n",
    "        #bboxes = utils.postprocess_boxes(pred_bbox, image_size, INPUT_SIZE, cfg.TEST.SCORE_THRESHOLD)\n",
    "        #bboxes = utils.nms(bboxes, cfg.TEST.IOU_THRESHOLD, method='nms')\n",
    "        bboxes = utils.postprocess_boxes(pred_bbox, image_size, INPUT_SIZE, cfg.TEST.SCORE_THRESHOLD)\n",
    "        bboxes = utils.nms(bboxes, cfg.TEST.IOU_THRESHOLD, method='nms')\n",
    "\n",
    "\n",
    "        if cfg.TEST.DECTECTED_IMAGE_PATH is not None:\n",
    "            image = utils.draw_bbox(image, bboxes)\n",
    "            cv2.imwrite(cfg.TEST.DECTECTED_IMAGE_PATH+image_name, image)\n",
    "        \n",
    "        required_classes = ['person','bicycle','car','diningtable','boat','motorbike','chair','dog','cup','bottle','bus','cat']\n",
    "\n",
    "        with open(predict_result_path, 'w') as f:\n",
    "            for bbox in bboxes:\n",
    "                coor = np.array(bbox[:4], dtype=np.int32)\n",
    "                score = bbox[4]\n",
    "                class_ind = int(bbox[5])\n",
    "                class_name = CLASSES[class_ind]\n",
    "                if class_name in required_classes:\n",
    "                    score = '%.4f' % score\n",
    "                    xmin, ymin, xmax, ymax = list(map(str, coor))\n",
    "                    bbox_mess = ' '.join([class_name, score, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "                    f.write(bbox_mess)\n",
    "                    print('\\t' + str(bbox_mess).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
